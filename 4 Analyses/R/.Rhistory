meanJol = tapply(nomiss$Jol, nomiss$Direction, mean)
meanR = tapply(nomiss$Recall, nomiss$Direction, mean)
meanJol
sdJol
meanR = tapply(nomiss$Recall, nomiss$Direction, mean)
sdR = tapply(nomiss$Recall, nomiss$Direction, sd, na.rm = T)
sdR
meanR
nJol = tapply(nomiss$Jol, nomiss$Direction, length)
nR = tapply(nomiss$Recall, nomiss$Direction, length)
meanR;sdR;nR
jfb = d.dep.t.avg(68.20625, 66.08839, 28.41285, 28.81500, 1120, a = .05) #d = .07
jfb.d = round(jfb$d, digits = 2)
jfb.d
print(R.t)[[5]] #T-values
pairwise.t.test(nomiss$Jol, nomiss$Direction, ##significant difference between Unrelated pairs and related pairs
paired = F, p.adjust.method = 'Bonferroni')
pairwise.t.test(nomiss$Jol, nomiss$Direction, ##significant difference between Unrelated pairs and related pairs
paired = F, p.adjust.method = 'bonferroni')
pairwise.t.test(nomiss$Recall, nomiss$Direction, ##all are significant
paired = F, p.adjust.method = 'bonferroni')
Jol.t = pairwise.t.test.with.t.and.df(nomiss$Jol, nomiss$Direction,
paired = F, p.adjust.method = 'bonferroni')
R.t = pairwise.t.test.with.t.and.df(nomiss$Recall, nomiss$Direction,
paired = F, p.adjust.method = 'bonferroni')
print(Jol.t)[[5]] #T-values
print(R.t)[[5]] #T-values
rfs = d.dep.t.avg(67.40741, 58.83929, 46.89169, 49.23445, 1120, a = .05) #d = 0.18
rfs.d = round(rfs$d, digits = 2)
rfs.d
model9 = aov(int.dat$diff ~ (int.dat$jol_bin*int.dat$direction))
nomiss.f = subset(nomiss,
nomiss$Direction == "F")
nomiss.b = subset(nomiss,
nomiss$Direction == "B")
nomiss.s = subset(nomiss,
nomiss$Direction == "S")
nomiss.u = subset(nomiss,
nomiss$Direction == "U")
##get rounded jols
nomiss.f$jol_bin = round(nomiss.f$Jol, -1)
nomiss.b$jol_bin = round(nomiss.b$Jol, -1)
nomiss.s$jol_bin = round(nomiss.s$Jol, -1)
nomiss.u$jol_bin = round(nomiss.u$Jol, -1)
##put data in wide format
##jol
f.jol = cast(nomiss.f, Subject ~ block, mean, value = 'Jol')
f.jol$mean_JOL = apply(f.jol, 1, mean)
f.jol$jol_bin = round(f.jol$mean_JOL, -1)
b.jol = cast(nomiss.b, Subject ~ block, mean, value = 'Jol')
b.jol$mean_JOL = apply(b.jol, 1, mean)
b.jol$jol_bin = round(b.jol$mean_JOL, -1)
s.jol = cast(nomiss.s, Subject ~ block, mean, value = 'Jol')
s.jol$mean_JOL = apply(s.jol, 1, mean)
s.jol$jol_bin = round(s.jol$mean_JOL, -1)
u.jol = cast(nomiss.u, Subject ~ block, mean, value = 'Jol')
u.jol$mean_JOL = apply(u.jol, 1, mean)
u.jol$jol_bin = round(u.jol$mean_JOL, -1)
##recall
f.recall = cast(nomiss.f, Subject ~ block, mean, value = 'Recall')
f.recall$mean_recall = apply(f.recall, 1, mean)
b.recall = cast(nomiss.b, Subject ~ block, mean, value = 'Recall')
b.recall$mean_recall = apply(b.recall, 1, mean)
s.recall = cast(nomiss.s, Subject ~ block, mean, value = 'Recall')
s.recall$mean_recall = apply(s.recall, 1, mean)
u.recall = cast(nomiss.u, Subject ~ block, mean, value = 'Recall')
u.recall$mean_recall = apply(u.recall, 1, mean)
##add direction column
f.recall$direction = rep("f", 28)
f.jol$direction = rep("f", 28)
b.recall$direction = rep("b", 28)
b.jol$direction = rep("b", 28)
s.recall$direction = rep("s", 28)
s.jol$direction = rep("s", 28)
u.recall$direction = rep("u", 28)
u.jol$direction = rep("u", 28)
##Put everything back together
int.recall = rbind(f.recall, b.recall, s.recall, u.recall)
int.jol = rbind(f.jol, b.jol, s.jol, u.jol)
int.recall = int.recall[ , -c(2:3)]
int.jol = int.jol[ , -c(2:3)]
int.dat = cbind(int.jol, int.recall)
int.dat = int.dat[ , -c(4:5)]
##get difference score
int.dat$mean_recall = int.dat$mean_recall * 100
int.dat$diff = int.dat$jol_bin - int.dat$mean_recall
library(car)
model9 = aov(int.dat$diff ~ (int.dat$jol_bin*int.dat$direction))
summary(model9)
library(lsr)
etas1 = etaSquared(model9)
bar3 = ggplot(long.dat, aes(Direction, Score, fill = Task))
bar3 = bar3 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol" = "white",
"Recall" = "dimgrey")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance")
ylim(0,100)
#labs(title="All Blocks")
bar3
dat = read.csv("ex2 final output.csv")
summary(dat)
library(ggplot2)
library(reshape)
##put recall on correct scale
dat$Scored_Response = (dat$Scored_Response * 100)
##remove out of range scores
dat$Jol_Response[dat$Jol_Response > 100] = NA
##get sample size
summary(dat$Subject) #n = 34
summary(dat)
##remove missing
nomiss3 = na.omit(dat)
colnames(nomiss3)[6] = "Jol"
colnames(nomiss3)[9] = "Recall"
####make the graph####
##melt the data
long.dat = melt(nomiss3, id = c("Subject", "Block",
"ListNum", "Direction", "ExperimentName", "cue_target",
"recall_response", "cue_prompt"))
summary(long.dat)
colnames(long.dat)[9] = "Task"
colnames(long.dat)[10] = "Score"
bar3 = ggplot(long.dat, aes(Direction, Score, fill = Task))
bar3 = bar3 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol" = "white",
"Recall" = "dimgrey")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance")
ylim(0,100)
#labs(title="All Blocks")
bar3
bar3 = ggplot(long.dat, aes(Direction, Score, fill = Task))
bar3 = bar3 +
stat_summary(fun.y = mean,
geom = "bar",
position = "dodge",
color = "Black") +
stat_summary(fun.data = mean_cl_normal,
geom = "errorbar",
position = position_dodge(width = 0.90),
width = 0.2,
color = "black") +
scale_fill_manual("Task",
values = c("Jol" = "white",
"Recall" = "dimgrey")) +
cleanup +
xlab("Direction") +
ylab("Mean Task Performance") +
ylim(0,100)
#labs(title="All Blocks")
bar3
knitr::include_graphics("plot1.png")
citr:::insert_citation()
12.11*40
484.4*2
968.8*.15
968.8-145.32
823-110-50
85-22)
85-22
n = 100
dbinom(100)
dbinom(50, 100, 50)
dbinom(50, 100, 2)
dbinom(50, 100, .5)
dbinom(50, 100, .5)
round(data.frame(0:100, probs), digits = 5)
probs = dbinom(50, 100, .5)
round(data.frame(0:100, probs), digits = 5)
plot(0:100, probs, type="h", xlim=c(0,100), ylim=c(0,.1))
probs = dbinom(0:100, 100, .5) ##get the probability
round(data.frame(0:100, probs), digits = 5)
plot(0:100, probs, type="h", xlim=c(0,100), ylim=c(0,.1))
points(0:100, probs, pch=16, cex=.5)
curve(dnorm(x, mean=50, sd=5), from=0, to=100, xlim = c(0, 100), ylim = c(0, 0.5), xlab = "x", add=T, col="blue")
sum(dbinom(45:55, size=100, prob=1/2))
sum(dbinom(50, size=100, prob=1/2))
length(probs)
probs = as.data.frame(probs)
subset(probs, Mod(probs$probs) == 0)
View(probs)
head = 1
tail = 0
prob = e
e
e = exp(1)
sample(c("Heads", "Tails"), n, rep = T)
Flip1Coin = function(n) sample(c("Heads", "Tails"), n, rep = T)
Flip1Coin(n)
sample(c("Heads", "Tails"), n, rep = T)
sample(c("Heads", "Tails"), n, rep = 100)
Flip1Coin = function(n) sample(c("Heads", "Tails"), n, rep = 100)
Flip1Coin(n)
sample(c("Heads", "Tails"), n, rep = 100)
Flip1Coin = sample(c("Heads", "Tails"), n, rep = 100)
pbinom(50, 100, .5)
dbinom(50, 100, .5)
dnorm(50)
dnorm(50/sqrt(24))
pbinom(50, size = 100, .5)
pbinom(48, size = 100, .5)
pbinom(52, size = 100, .5)
pbinom(71, size = 100, .5)
m = 100 * .5
sd1 = sqrt(100 * .5 *.5)
1 - dnorm(50, mean = m, sd = sd1)
1 - pnorm(50, mean = m, sd = sd1)
x = c(0:100)
length(x)
mod(x, 2)
Mod(x)
Mod(x, 2)
.5*10
.75*7.5
.6*7.5
.7*7.5
.65*7.5
.68*7.5
.625*7.5
.667*7.5
.667*5
.667*4
.667*4.25
.667*8
.6 *8
.62 *8
.63 *8
.625 *8
.625 * 4
25*60
1500/5
install.packages("installr")
installr::installr()
library(ez)
library(reshape)
devtools::install_github("npm27/lrd")
devtools::install_github("npm27/lrd")
devtools::install_github("npm27/lrd")
shiny::runApp('GitHub/lrd/shiny')
shiny::runApp('lrdSHINY')
runApp('lrdSHINY')
runApp('lrdSHINY')
setwd("~/GitHub/BOI-Norms/3 Output")
####Combine .csv files into master datasheet####
setwd("./RAW")
#Get the files names
files = list.files(pattern = "*.csv")
#read everything in and merge into one dataframe.
dat = do.call(rbind, lapply(files, function(x) read.csv(x, stringsAsFactors = FALSE)))
setwd("..")
##remove instruction trials
unique(dat$Procedure.Trial.Type)
dat2 = subset(dat,
dat$Procedure.Trial.Type != "Instruct")
##Remove practice trials
dat2 = subset(dat2,
dat2$Procedure.Item < 3001)
##Write to .csv
write.csv(dat2, file = "merged_9_19.csv", row.names = F)
setwd("~/GitHub/BOI-Norms/4 Analyses/R")
####Set up####
##libraries
#Not sure if I'll be using all of these
library(dplyr)
library(here)
#Spelling
library(hunspell)
library(tidytext)
library(stringi)
library(stringr)
#Lemmas
library(koRpus)
library(koRpus.lang.en)
library(tokenizers)
library(textstem)
library(udpipe)
#stopwords
library(stopwords)
##read in data
master = read.csv("0-Data/merged_9_19.csv", stringsAsFactors = F)
##drop unused column
dat = master[ , -c(2:4, 6:7, 9:11, 14:17, 19, 22:24, 26:27, 30:32,34)]
View(dat)
#useful column names
colnames(dat)[12] = "affordance_response"
#Check for NAs
table(is.na(dat$affordance_response))
#remove nas
dat = na.omit(dat)
####Fix Spelling and Remove White Space####
##normalize all responses to lowercase
dat$affordance_response = tolower(dat$affordance_response)
##Spelling
#Extract a list of words
tokens = unnest_tokens(tbl = dat, output = token, input = affordance_response)
wordlist = unique(tokens$token)
#Run the spell check
spelling.errors = hunspell(wordlist)
spelling.errors = unique(unlist(spelling.errors))
spelling.sugg = hunspell_suggest(spelling.errors, dict = dictionary("en_US"))
#Pick the first spelling suggestion
spelling.sugg = unlist(lapply(spelling.sugg, function(x) x[1]))
#manually check errors
spell_check = cbind(spelling.sugg, spelling.errors)
#Write to file and manually confirm
write.csv(spell_check, file = "spell_check.csv", row.names = F)
#read back in the checked output
spell_check = read.csv("spell_check.csv", stringsAsFactors = F)
spelling.sugg = as.list(spell_check$spelling.sugg)
#Now make a spelling dictionary
spelling.sugg = tolower(spelling.sugg)
spelling.sugg = as.list(spelling.sugg)
spelling.dict = as.data.frame(cbind(spelling.errors, spelling.sugg))
spelling.dict$spelling.pattern = paste0("\\b", spelling.dict$spelling.errors, "\\b")
##Remove white space from responses
#Parse affordances
tokens = unnest_tokens(tbl = dat, output = token,
input = affordance_response, token = stringr::str_split,
pattern = " |\\, |\\.|\\,|\\;")
tokens$token = trimws(tokens$token,
which = c("both", "left", "right"),
whitespace = "[ \t\r\n]")
#Remove empty affordance responses
tokens = tokens[!tokens$token == "", ]
#replace misspelled words w/ corrected
tokens$corrected = stri_replace_all_regex(str = tokens$token,
pattern = spelling.dict$spelling.pattern,
replacement = spelling.dict$spelling.sugg,
vectorize_all = FALSE)
#Fix column names
colnames(tokens)[12:13] = c("affordance", "affordance_corrected")
##Write spelled checked data to .csv
write.csv(tokens, file = "spell_checked.csv", row.names = F)
####Lemmatization####
dat = read.csv("spell_checked.csv", stringsAsFactors = F)
View(dat)
#extract updated tokens
tokens = unnest_tokens(tbl = dat, output = word, input = affordance_corrected)
cuelist = unique(tokens$Stimuli.Cue)
##okay, I think this does what I want.
dat$affordance_lemma = lemmatize_strings(dat$affordance_corrected)
##Oooh, I like this as an alternative to treetagger.
#does it work on DF columns?
lemmatized = udpipe(dat$affordance_corrected, "english")
View(lemmatized)
58787-58295
#remove spaces from the middle of words
dat$affordance_corrected = stringr::str_remove_all(dat$affordance_corrected, " ")
##Remove stop words
no_stop = dat %>%
filter(!grepl("[[:punct:]]", affordance_corrected)) %>% #Remove punctuation
filter(!affordance_corrected %in% stopwords(language = "en", source = "snowball")) %>% #remove stopwords
filter(!grepl("[[:digit:]]+", affordance_corrected)) %>% #remove numbers
filter(!is.na(affordance_corrected))
temp = data.frame(table(no_stop$affordance_corrected)) #If you View temp, you can see that there's parenthesis, puncation, weird spaces, etc.
#remove extra spaces
no_stop$affordance_corrected = gsub(" ", "", no_stop$affordance_corrected)
#Remove 's
no_stop$affordance_corrected = gsub("'s", "", no_stop$affordance_corrected)
#Remove 't
no_stop$affordance_corrected = gsub("'t", "t", no_stop$affordance_corrected)
#Remove any stopwords that might have been generated in lines 139/142
no_stop = no_stop %>%
filter(!affordance_corrected %in% stopwords(language = "en", source = "snowball"))
##Write to .csv for lemmatization w/ Python
write.csv(no_stop, file = "cleaned_9_19_21.csv", row.names = F)
View(no_stop)
View(dat)
##This code is adopted from Buchanan et al. 2019's primer on processing feature production norms
#https://link.springer.com/article/10.1007/s10339-019-00939-6
####Set up####
##libraries
#Not sure if I'll be using all of these
library(dplyr)
library(here)
#Spelling
library(hunspell)
library(tidytext)
library(stringi)
library(stringr)
#Lemmas
library(koRpus)
library(koRpus.lang.en)
library(tokenizers)
library(textstem)
library(udpipe)
#stopwords
library(stopwords)
##read in data
master = read.csv("0-Data/merged_9_19.csv", stringsAsFactors = F)
##drop unused column
dat = master[ , -c(2:4, 6:7, 9:11, 14:17, 19, 22:24, 26:27, 30:32,34)]
#useful column names
colnames(dat)[12] = "affordance_response"
#Check for NAs
table(is.na(dat$affordance_response))
#remove nas
dat = na.omit(dat)
####Fix Spelling and Remove White Space####
##normalize all responses to lowercase
dat$affordance_response = tolower(dat$affordance_response)
##Spelling
#Extract a list of words
tokens = unnest_tokens(tbl = dat, output = token, input = affordance_response)
wordlist = unique(tokens$token)
#Run the spell check
spelling.errors = hunspell(wordlist)
spelling.errors = unique(unlist(spelling.errors))
spelling.sugg = hunspell_suggest(spelling.errors, dict = dictionary("en_US"))
#Pick the first spelling suggestion
spelling.sugg = unlist(lapply(spelling.sugg, function(x) x[1]))
#manually check errors
spell_check = cbind(spelling.sugg, spelling.errors)
#Write to file and manually confirm
write.csv(spell_check, file = "spell_check.csv", row.names = F)
#read back in the checked output
spell_check = read.csv("spell_check.csv", stringsAsFactors = F)
spelling.sugg = as.list(spell_check$spelling.sugg)
#Now make a spelling dictionary
spelling.sugg = tolower(spelling.sugg)
spelling.sugg = as.list(spelling.sugg)
spelling.dict = as.data.frame(cbind(spelling.errors, spelling.sugg))
spelling.dict$spelling.pattern = paste0("\\b", spelling.dict$spelling.errors, "\\b")
##Remove white space from responses
#Parse affordances
tokens = unnest_tokens(tbl = dat, output = token,
input = affordance_response, token = stringr::str_split,
pattern = " |\\, |\\.|\\,|\\;")
tokens$token = trimws(tokens$token,
which = c("both", "left", "right"),
whitespace = "[ \t\r\n]")
#Remove empty affordance responses
tokens = tokens[!tokens$token == "", ]
#replace misspelled words w/ corrected
tokens$corrected = stri_replace_all_regex(str = tokens$token,
pattern = spelling.dict$spelling.pattern,
replacement = spelling.dict$spelling.sugg,
vectorize_all = FALSE)
#Fix column names
colnames(tokens)[12:13] = c("affordance", "affordance_corrected")
##Write spelled checked data to .csv
write.csv(tokens, file = "spell_checked.csv", row.names = F)
####Lemmatization####
dat = read.csv("spell_checked.csv", stringsAsFactors = F)
#extract updated tokens
tokens = unnest_tokens(tbl = dat, output = word, input = affordance_corrected)
cuelist = unique(tokens$Stimuli.Cue)
##okay, I think this does what I want.
dat$affordance_lemma = lemmatize_strings(dat$affordance_corrected)
##Erin's walkthrough used TreeTagger for this
##Okay, TreeTagger HATES windows and I can't get it to work, what else can I do?
##Treetagger also pulls part of speech, which would be nice to have.
##what about udpipe?
#Example
#x = c(doc_a = "In our last meeting, someone said that we are meeting again tomorrow",
#      doc_b = "It's better to be good at being the best")
#anno = udpipe(x, "english")
#anno[, c("doc_id", "sentence_id", "token", "lemma", "upos")]
##Oooh, I like this as an alternative to treetagger.
#does it work on DF columns?
#lemmatized = udpipe(dat$affordance_corrected, "english")
#It does, but there are a few issues. Mainly it ended up with a few extra tokens somehow.
#Get only the overlapping tokens.
#Okay, I think i figured this out. If any words still have spaces in them, udpipe breaks it in two.
#I thought I had removed spaces up above but something must have gotten off.
#Okay, looks like some spaces get reintroduced line 82 when fixing spelling (e.g., "peprally" got turned back into "pep rally")
#remove spaces from the middle of words
dat$affordance_corrected = stringr::str_remove_all(dat$affordance_corrected, " ")
#Stop words also mess it up. Remove stop words here:
#Now I need to remove punctuation/weirdness
##Remove stop words
no_stop = dat %>%
filter(!grepl("[[:punct:]]", affordance_corrected)) %>% #Remove punctuation
filter(!affordance_corrected %in% stopwords(language = "en", source = "snowball")) %>% #remove stopwords
filter(!grepl("[[:digit:]]+", affordance_corrected)) %>% #remove numbers
filter(!is.na(affordance_corrected))
temp = data.frame(table(no_stop$affordance_corrected)) #If you View temp, you can see that there's parenthesis, puncation, weird spaces, etc.
#remove extra spaces
no_stop$affordance_corrected = gsub(" ", "", no_stop$affordance_corrected)
#Remove 's
no_stop$affordance_corrected = gsub("'s", "", no_stop$affordance_corrected)
#Remove 't
no_stop$affordance_corrected = gsub("'t", "t", no_stop$affordance_corrected)
#Remove any stopwords that might have been generated in lines 139/142
no_stop = no_stop %>%
filter(!affordance_corrected %in% stopwords(language = "en", source = "snowball"))
no_stop %>%
filter(!affordance_corrected %in% stopwords(language = "en", source = "snowball"))
View(master)
