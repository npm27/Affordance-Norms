setwd("C:/Users/nickm/OneDrive/Documents/GitHub/BOI-Norms/4 Analyses/R/PNOM Analysis")
####Set up####
##libraries
library(reshape)
library(psych)
library(dplyr)
##turn off scientific notation
options(scipen = 999)
##read in data
boi = read.csv("Data/Pexman BOI Norms.csv")
aff = read.csv("Data/Affordance Norms.csv")
View(aff)
####Get the strongest affordance pairing for each cue####
##use a loop?
temp = data.frame()
cuelist = unique(aff$cue)
print(temp2)
for(i in cuelist){
temp2 = subset(aff,
aff$cue == i)
print(temp2)
}
for(i in cuelist){
temp2 = subset(aff,
aff$cue == i)
temp2 = temp2[1, ]
print(temp2)
}
for(i in cuelist){
temp2 = subset(aff,
aff$cue == i)
temp2 = temp2[1, ]
temp = rbind(temp2, temp)
}
View(temp)
aff2 = temp
mean(aff2$AFS)
mean(aff2$AFSS)
corr.test(aff2$AFS, aff2$AFSS)
cor.test(aff2$AFS, aff2$AFSS)
####Okay, correlation between highest AFS and BOI?####
##merge the datasets
combined = merge(aff2, boi[ , -2], by = "cue")
####Okay, correlation between highest AFS and BOI?####
##merge the datasets
colnames(boi)[1] = "cue"
combined = merge(aff2, boi[ , -2], by = "cue")
##now run the correlation
cor.test(combined$AFS, combined$Mean)
View(combined)
fsg = read.csv("Data/Nelson Norms.csv")
fsg = read.csv("Data/Nelson Norms.csv")
####What about association strength?####
colnames(combined)[2] = "target"
View(fsg)
####What about association strength?####
colnames(combined)[1:2] = c("CUE", "TARGET")
combined2 = merge(combined, fsg, by = c("CUE", "TARGET"))
View(combined2)
combined$CUE = toupper(combined$CUE)
combined$TARGET = toupper(combined$TARGET)
View(combined)
combined2 = merge(combined, fsg, by = c("CUE", "TARGET"))
500/3000
548/3000
cor.test(combined2$AFS, combined2$FSG)
cor.test(combined2$AFS, combined2$Mean)
cor.test(combined2$AFS, combined2$QCON)
##Looking at the full AFS dataset
aff$cue = toupper(aff$cue)
aff$response = toupper(aff$response)
colnames(aff)[1:2] = c("CUE", "TARGET")
combined3 = merge(aff, fsg, by = c("CUE", "TARGET"))
cor.test(combined3$AFS, combined3$FSG)
##now run the correlation
cor.test(combined$AFS, combined$Mean) #again, a weak correlation
cor.test(combined3$AFS, combined3$FSG)
mean(combined3$AFSS)
View(combined3)
mean(combined3$QSS)
mean(aff$AFS)
mean(fsg$FSG)
####Set up####
##libraries
library(reshape)
library(psych)
library(dplyr)
##turn off scientific notation
options(scipen = 999)
##read in data
boi = read.csv("Data/Pexman BOI Norms.csv")
aff = read.csv("Data/Affordance Norms.csv")
con = read.csv("Data/Brysbaert Con Norms.csv")
##get the aff set sizes and unique items
aff2 <- aff[ , -c(2:3)] %>%
arrange(cue, -AFSS) %>%
filter(duplicated(cue) == FALSE)
##merge affordance data w/ boi and test for correlation
colnames(boi)[1] = "cue"
combined = merge(aff2, boi[ , -2], by = "cue")
cor.test(combined$AFSS, combined$Mean)
plot(combined$AFSS, combined$Mean)
##merge affordance data w/ con and test for correlation
colnames(con)[1] = "cue"
combined2 = merge(aff2, con, by = "cue")
cor.test(combined2$AFSS, combined2$Conc.M) #concreteness
plot(combined2$AFSS, combined2$Conc.M)
cor.test(combined$AFSS, combined$Mean)
####Set up####
##libraries
library(reshape)
library(psych)
library(dplyr)
##turn off scientific notation
options(scipen = 999)
##read in data
boi = read.csv("Data/Pexman BOI Norms.csv")
aff = read.csv("Data/Affordance Norms.csv")
fsg = read.csv("Data/Nelson Norms.csv")
####Get the strongest affordance pairing for each cue####
##use a loop?
temp = data.frame()
cuelist = unique(aff$cue)
for(i in cuelist){
temp2 = subset(aff,
aff$cue == i)
temp2 = temp2[1, ]
temp = rbind(temp2, temp)
}
aff2 = temp
##some descriptives
mean(aff2$AFS)
mean(aff2$AFSS)
cor.test(aff2$AFS, aff2$AFSS) ##Not too surprising that the bigger the set size, the lower the AFS
####Okay, correlation between highest AFS and BOI?####
##merge the datasets
colnames(boi)[1] = "cue"
combined = merge(aff2, boi[ , -2], by = "cue")
##now run the correlation
cor.test(combined$AFS, combined$Mean) #again, a weak correlation
####What about association strength?####
##Looking at the subset
colnames(combined)[1:2] = c("CUE", "TARGET")
combined$CUE = toupper(combined$CUE)
combined$TARGET = toupper(combined$TARGET)
combined2 = merge(combined, fsg, by = c("CUE", "TARGET"))
cor.test(combined2$AFS, combined2$FSG) #.20
##Looking at the full AFS dataset
aff$cue = toupper(aff$cue)
aff$response = toupper(aff$response)
colnames(aff)[1:2] = c("CUE", "TARGET")
combined3 = merge(aff, fsg, by = c("CUE", "TARGET"))
cor.test(combined3$AFS, combined3$FSG)
mean(combined3$AFSS)
mean(combined3$QSS)
cor.test(combined3$AFS, combined3$FSG)
cor.test(combined2$AFS, combined2$FSG) #.20
####Set up####
##libraries
library(reshape)
library(psych)
library(dplyr)
##turn off scientific notation
options(scipen = 999)
##read in data
boi = read.csv("Data/Pexman BOI Norms.csv")
aff = read.csv("Data/Affordance Norms.csv")
con = read.csv("Data/Brysbaert Con Norms.csv")
##get the aff set sizes and unique items
aff2 <- aff[ , -c(2:3)] %>%
arrange(cue, -AFSS) %>%
filter(duplicated(cue) == FALSE)
##merge affordance data w/ boi and test for correlation
colnames(boi)[1] = "cue"
combined = merge(aff2, boi[ , -2], by = "cue")
cor.test(combined$AFSS, combined$Mean)
plot(combined$AFSS, combined$Mean)
##merge affordance data w/ con and test for correlation
colnames(con)[1] = "cue"
combined2 = merge(aff2, con, by = "cue")
cor.test(combined2$AFSS, combined2$Conc.M) #concreteness
plot(combined2$AFSS, combined2$Conc.M)
cor.test(combined$AFSS, combined$Mean)
####Set up####
##libraries
library(reshape)
library(psych)
library(dplyr)
##turn off scientific notation
options(scipen = 999)
##read in data
boi = read.csv("Data/Pexman BOI Norms.csv")
aff = read.csv("Data/Affordance Norms.csv")
fsg = read.csv("Data/Nelson Norms.csv")
####Get the strongest affordance pairing for each cue####
##use a loop?
temp = data.frame()
cuelist = unique(aff$cue)
for(i in cuelist){
temp2 = subset(aff,
aff$cue == i)
temp2 = temp2[1, ]
temp = rbind(temp2, temp)
}
aff2 = temp
##some descriptives
mean(aff2$AFS)
mean(aff2$AFSS)
cor.test(aff2$AFS, aff2$AFSS) ##Not too surprising that the bigger the set size, the lower the AFS
####Okay, correlation between highest AFS and BOI?####
##merge the datasets
colnames(boi)[1] = "cue"
combined = merge(aff2, boi[ , -2], by = "cue")
##now run the correlation
cor.test(combined$AFS, combined$Mean) #again, a weak correlation
####What about association strength?####
##Looking at the subset
colnames(combined)[1:2] = c("CUE", "TARGET")
combined$CUE = toupper(combined$CUE)
combined$TARGET = toupper(combined$TARGET)
combined2 = merge(combined, fsg, by = c("CUE", "TARGET"))
cor.test(combined2$AFS, combined2$FSG) #.19
##Looking at the full AFS dataset
aff$cue = toupper(aff$cue)
aff$response = toupper(aff$response)
colnames(aff)[1:2] = c("CUE", "TARGET")
combined3 = merge(aff, fsg, by = c("CUE", "TARGET"))
cor.test(combined3$AFS, combined3$FSG)
mean(combined3$AFSS)
mean(combined3$QSS)
####Set up####
##libraries
library(reshape)
library(psych)
library(dplyr)
##turn off scientific notation
options(scipen = 999)
##read in data
boi = read.csv("Data/Pexman BOI Norms.csv")
aff = read.csv("Data/Affordance Norms.csv")
fsg = read.csv("Data/Nelson Norms.csv")
####Get the strongest affordance pairing for each cue####
##use a loop?
temp = data.frame()
cuelist = unique(aff$cue)
for(i in cuelist){
temp2 = subset(aff,
aff$cue == i)
temp2 = temp2[1, ]
temp = rbind(temp2, temp)
}
aff2 = temp
##some descriptives
mean(aff2$AFS)
mean(aff2$AFSS)
cor.test(aff2$AFS, aff2$AFSS) ##Not too surprising that the bigger the set size, the lower the AFS
####Okay, correlation between highest AFS and BOI?####
##merge the datasets
colnames(boi)[1] = "cue"
combined = merge(aff2, boi[ , -2], by = "cue")
##now run the correlation
cor.test(combined$AFS, combined$Mean) #again, a weak correlation
####What about association strength?####
##Looking at the subset
colnames(combined)[1:2] = c("CUE", "TARGET")
combined$CUE = toupper(combined$CUE)
combined$TARGET = toupper(combined$TARGET)
combined2 = merge(combined, fsg, by = c("CUE", "TARGET"))
cor.test(combined2$AFS, combined2$FSG) #.19
##Looking at the full AFS dataset
aff$cue = toupper(aff$cue)
aff$response = toupper(aff$response)
colnames(aff)[1:2] = c("CUE", "TARGET")
combined3 = merge(aff, fsg, by = c("CUE", "TARGET"))
cor.test(combined3$AFS, combined3$FSG)
mean(combined3$AFSS)
mean(combined3$QSS)
cor.test(combined2$AFS, combined2$FSG) #.19
